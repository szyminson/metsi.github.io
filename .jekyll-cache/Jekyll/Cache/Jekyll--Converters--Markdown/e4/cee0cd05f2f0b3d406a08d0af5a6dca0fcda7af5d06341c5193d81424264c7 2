I"E<p>Nasta pitek, a zarazem tak偶e czas, aby uraczy nasze oczy kolejnym zbiorem przykad贸w. Dzisiaj zbudujemy model klasyfikacji, dokonamy za jego pomoc predykcji oraz ocenimy, jak dobrze nasz klasyfikator radzi sobie z zadanym problemem. Nie tramy wic czasu i zabierzmy si do pracy!</p>

<!--more-->

<h2 id="przygotowanie-zbioru-danych">Przygotowanie zbioru danych</h2>

<h3 id="wczytanie-wczeniej-wygenerowanego-zbioru-danych">Wczytanie wczeniej wygenerowanego zbioru danych</h3>

<p>We wczeniejszych przykadach nauczylimy si generowa syntetyczny zbi贸r danych, zapisywa go do pliku CSV oraz takowe pliki wczytywa. Zacznijmy wic dzisiejsze zadanie od wczytania wczeniej przygotowanego zestawu danych, kt贸ry znajduje si w pliku <code class="highlighter-rouge">dataset.csv</code> (wygodnie dostpnym do pobrania <a href="https://github.com/metsi/metsi.github.io/blob/master/examples/dataset.csv">tutaj</a>).</p>

<p>Zestaw danych zosta wygenerowany przy pomocy dobrze nam znanego ju偶 kodu:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">flip_y</span><span class="o">=</span><span class="mf">.05</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1410</span><span class="p">,</span>
    <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Wczytywanie problemu i jego podzia na <em>zbi贸r danych</em> i <em>zbi贸r etykiet</em>, dla przypomnienia, realizujemy w spos贸b nastpujcy:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">"dataset.csv"</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div>

<p>Mamy gotowy ju偶 nasz <code class="highlighter-rouge">X</code> i <code class="highlighter-rouge">y</code>, je偶eli jednak chcemy aby nasze badania nosiy chocia偶by znamiona rzetelnoci, to w 偶adnym razie nie mo偶emy na tym poprzesta.</p>

<h3 id="podzia-danych-na-zbi贸r-uczcy-oraz-zbi贸r-testowy">Podzia danych na zbi贸r uczcy oraz zbi贸r testowy</h3>

<p>Przed wykonaniem jakichkolwiek bada musimy pamita, aby podzieli nasz zestaw danych na <em>zbi贸r uczcy</em> oraz <em>zbi贸r testowy</em>. W zadaniu klasyfikacji <em>zbi贸r uczcy</em> zawiera znane nam instancje problemu, kt贸re zostay wczeniej poetykietowane i posu偶 do wytrenowania wybranego przez nas modelu, aby potem m贸g on generalizowa zdobyt wiedz w odniesieniu do instancji, kt贸rych wczeniej nie widzia (czyli <em>zbioru testowego</em>). Trenowanie i testowanie modelu na tym samym zbiorze danych jest absolutnie niedopuszczalne i uzyskane w ten spos贸b wyniki w 偶aden spos贸b nie odzwierciedlaj faktycznej zdolnoci predykcyjnej klasyfikatora.</p>

<p>W dzisiejszym przykadzie skorzystamy z funkcji <code class="highlighter-rouge">train_test_split()</code>, za kt贸rej pomoc dokonamy pojedynczego podziau naszego zbioru danych. Jest to podejcie zdecydowanie intelektualnie nienachalne i urgajce godnoci naukowca, niemniej jednak przedstawimy je tutaj (<strong>i tylko tutaj</strong>) jako najprostszy mo偶liwy przykad podziau danych na potrzeby zadania klasyfikacji. W przysz rod nauczymy si u偶ywa <em>walidacji krzy偶owej</em>, kt贸ra pozwoli nam na rzetelne przeprowadzenie bada i to wanie z niej bdziemy korzysta we wszystkich przyszych starciach z uczeniem maszynowym.</p>

<p>Wracajc jednak do tera藕niejszoci, przygotujmy nasz <em>zbi贸r testowy</em> oraz <em>zbi贸r uczcy</em> za pomoc <code class="highlighter-rouge">train_test_split()</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</code></pre></div></div>
<p>W tym przypadku, jako argumenty funkcji, przekaza musimy tylko dwa parametry t.j. dobrze ju偶 nam znany i lubiany <code class="highlighter-rouge">random_state</code> oraz <code class="highlighter-rouge">test_size</code>, kt贸ry m贸wi nam o tym, jaki procent wszystkich danych zostanie wykorzystany do testowania naszego modelu. Tutaj decydujemy si na wykorzystanie 70% danych do uczenia oraz 30% do testowania klasyfikatora.</p>

<h2 id="klasyfikacja">Klasyfikacja</h2>

<h3 id="inicjalizacja-i-budowa-modelu-klasyfikacji">Inicjalizacja i budowa modelu klasyfikacji</h3>

<p>Teraz, gdy przygotowalimy ju偶 nasze dane, mo偶emy w kocu przej do inicjalizacji oraz wytrenowania modelu klasyfikacji. Skorzystamy z prostego klasyfikatora probabilistycznego, kt贸rym jest <em>Naiwny klasyfikator bayesowski</em> w wersji opartej na rozkadzie normalnym (rozkadzie Gaussa). Jest on nazywany <em>naiwnym</em>, poniewa偶 zakada niezale偶no od siebie cech problemu, a implementuje go klasa <code class="highlighter-rouge">GaussianNB</code>.</p>

<p>W celu dopasowania naszego modelu do danych uczcych wywoujemy metod <code class="highlighter-rouge">fit()</code>, kt贸ra przyjmuje kolejno <em>zbi贸r danych</em> oraz <em>zbi贸r etykiet</em> naszego zbioru uczcego:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>
<p>Nasz model zosta ju偶 wyuczony na poetykietowanych danych, mo偶emy wic w kocu przystpi do predykcji.</p>

<h3 id="wyznaczenie-macierzy-wsparcia-oraz-predykcji">Wyznaczenie macierzy wsparcia oraz predykcji</h3>

<p>Klasyfikatory zaimplementowane w bibliotece <code class="highlighter-rouge">scikit-learn</code> implementuj metod <code class="highlighter-rouge">predict()</code>, kt贸ra pozwala nam na bezporednie uzyskanie etykiet przyporzdkowanych nieznanym instancjom przez klasyfikator. My jednak, 偶eby nie byo tak atwo, nie skorzystamy z tej metody.</p>

<p>Dziki temu, 偶e zastosowany przez nas model jest probabilistyczny, mo偶emy poprosi go o zwr贸cenie <em>macierzy wspar</em>. Liczba wierszy tej macierzy jest r贸wna liczbie instancji problemu w <em>zbiorze testowym</em> (czyli u nas 30), a liczba kolumn r贸wna jest liczbie klas problemu (w naszym przypadku problem jest binarny, wic mamy dwie kolumny). Ka偶dy z wierszy macierzy odpowiada <em>wektorowi wspar</em> zwr贸conemu przez model dla danej klasyfikowanej instancji problemu. Wartoci w tym wektorze m贸wi nam o tym, z jakim prawdopodobiestwem klasyfikowana instancja nale偶y do danej klasy. <em>Macierz wspar</em> uzyska mo偶emy korzystajc z metody <code class="highlighter-rouge">predict_proba()</code> i podajc jako jej argument nasz testowy zbi贸r danych:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class_probabilities</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Class probabilities:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">class_probabilities</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Class probabilities:
&gt;&gt; [[2.57883436e-06 9.99997421e 01]
&gt;&gt; [1.99658559e-06 9.99998003e-01]
&gt;&gt; [9.90973563e-01 9.02643748e-03]
&gt;&gt; [5.47593735e-05 9.99945241e-01]
&gt;&gt; [9.98382405e-01 1.61759531e-03]
...
</code></pre></div></div>

<p>Posiadajc wiedz o prawdopodobiestwach przynale偶noci instancji ze <em>zbioru testowego</em> do klas, mo偶emy w prosty spos贸b wyznaczy predykcj. Zrobimy to zakadajc, 偶e ka偶da z instancji testowych nale偶y do tej klasy problemu, dla kt贸rej prawdopodobiestwo przynale偶noci jest najwiksze.</p>

<p>Mo偶emy dokona tego bardzo sprawnie za pomoc funkcji <code class="highlighter-rouge">argmax()</code>, kt贸ra zwr贸ci nam dla ka偶dego wiersza indeks kolumny, w kt贸rej wystpia najwiksza warto. W tym celu podajemy jako argumenty wczeniej uzyskan <em>macierz wspar</em> oraz o, po kt贸rej chcemy si porusza:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_probabilities</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Predicted labels:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Predicted labels:
&gt;&gt; [1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0]
</code></pre></div></div>

<p>W celach cakowicie ilustracyjnych, wypiszemy teraz obok siebie prawdziwe etykiety naszego <em>zbioru testowego</em> (<code class="highlighter-rouge">y_test</code>) oraz wyznaczon przez nas predykcj (<code class="highlighter-rouge">predict</code>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"True labels:     "</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Predicted labels:"</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; True labels:      [1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0]
&gt;&gt; Predicted labels: [1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0]
</code></pre></div></div>

<p>Jako, 偶e mamy tutaj do czynienia zaledwie z 30 instancjami problemu, ju偶 na pierwszy rzut oka mo偶emy stwierdzi, 偶e oba wektory nieznacznie r贸偶ni si od siebie. wiadczy to o tym, 偶e nasza predykcja nie jest idealna (i w praktyce nigdy idealna nie bdzie), ale oczywicie ocena dziaania naszego modelu w ten spos贸b byaby niewygodna. Potrzebujemy konkretnej wartoci, kt贸ra powiem nam jak dobry w tym przypadku jest nasz klasyfikator.</p>

<h3 id="ocena-jakoci-klasyfikacji-naszego-modelu">Ocena jakoci klasyfikacji naszego modelu</h3>

<p>Udao nam si dotrze do ostatniego dzisiejszego zagadnienia, a mianowicie do oceny jakoci klasyfikacji. Istnieje wiele metryk ewaluacji (o nich nauczymy si p贸藕niej przy okazji rozmowy o danych niezbalansowanych), ale w dzisiejszym przykadzie wystarczy nam najprostsza z nich, a mianowicie jako klasyfikacji. Informuje nas ona o tym, jaki procent instancji w <em>zbiorze testowym</em> zosta przez nas zaklasyfikowany poprawnie i sprawdza si w przypadku problem贸w zbalansowanych, czyli takich, w kt贸rych liczba instancji nale偶cych do obu klas jest stosunkowo podobna.</p>

<p>Klasyfikatory w bibliotece <code class="highlighter-rouge">scikit-learn</code> implementuj metod <code class="highlighter-rouge">score()</code>, kt贸ra pozwala nam na wyznaczenie jakoci klasyfikacji. My jednak skorzystamy z osobnej funkcji <code class="highlighter-rouge">accuracy_score()</code>, dziki kt贸rej uzyskamy t warto na podstawie wyznaczonej przez nas w poprzednim kroku predykcji. W ten spos贸b przyzwyczaimy si do samodzielnego przeprowadzania predykcji i wyznaczania metryki ewaluacji, co oka偶e si konieczne w przypadku budowania wasnych modeli klasyfikacji (zwaszcza zespoowych) oraz radzenia sobie z danymi niezbalansowanymi.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy score:</span><span class="se">\n</span><span class="s"> </span><span class="si">%.2</span><span class="s">f"</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Accuracy score:
&gt;&gt; 0.93
</code></pre></div></div>

<p>Jak widzimy, nasz model osign 93% jakoci klasyfikacji. Jest to wynik bardzo dobry, ale niestety wynikajcy g贸wnie z prostoty problemu, kt贸rym si dzisiaj zajmowalimy.</p>

<p>Dodatkowo, je偶eli chcemy dowiedzie si wicej o tym jak nasz model si zachowa, mo偶emy wyznaczy za pomoc funkcji <code class="highlighter-rouge">confusion_matrix()</code> dobrze znan nam z wykadu <em>macierz konfuzji</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Confusion matrix: </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">cm</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Confusion matrix:
&gt;&gt; [[13  0]
&gt;&gt; [ 2 15]]
</code></pre></div></div>

<p>Dziki temu dowiedzielimy si, 偶e nasz klasyfikator popeni dwa bdy polegajce na zaklasyfikowaniu obiektu klasy pozytywnej jako obiekt klasy negatywnej (warto False Negative = 2).</p>

<p>Uff, to ju偶 wszystko na dzisiaj. W przysz rod nauczymy si przeprowadza eksperymenty po ludzku, czyli z wykorzystaniem <em>walidacji krzy偶owej</em>. A do tego czasu mo偶emy by dumni ze zdobytej dzi podstawowej wiedzy!</p>

<p><img src="/examples/kod2neo.jpg" alt="" /></p>
:ET