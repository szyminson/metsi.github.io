I"dE<p>Nastał piątek, a zarazem także czas, aby uraczyć nasze oczy kolejnym zbiorem przykładów. Dzisiaj zbudujemy model klasyfikacji, dokonamy za jego pomocą predykcji oraz ocenimy, jak dobrze nasz klasyfikator radzi sobie z zadanym problemem. Nie traćmy więc czasu i zabierzmy się do pracy!</p>

<!--more-->

<h2 id="przygotowanie-zbioru-danych">Przygotowanie zbioru danych</h2>

<h3 id="wczytanie-wcześniej-wygenerowanego-zbioru-danych">Wczytanie wcześniej wygenerowanego zbioru danych</h3>

<p>We wcześniejszych przykładach nauczyliśmy się generować syntetyczny zbiór danych, zapisywać go do pliku CSV oraz takowe pliki wczytywać. Zacznijmy więc dzisiejsze zadanie od wczytania wcześniej przygotowanego zestawu danych, który znajduje się w pliku <code class="highlighter-rouge">dataset.csv</code> (wygodnie dostępnym do pobrania <a href="examples/dataset.csv">tutaj</a>).</p>

<p>Zestaw danych został wygenerowany przy pomocy dobrze nam znanego już kodu:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">make_classification</span><span class="p">(</span>
    <span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_features</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">n_informative</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">n_repeated</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">n_redundant</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">flip_y</span><span class="o">=</span><span class="mf">.05</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">1410</span><span class="p">,</span>
    <span class="n">n_clusters_per_class</span><span class="o">=</span><span class="mi">1</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Wczytywanie problemu i jego podział na <em>zbiór danych</em> i <em>zbiór etykiet</em>, dla przypomnienia, realizujemy w sposób następujący:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">dataset</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">genfromtxt</span><span class="p">(</span><span class="s">"dataset.csv"</span><span class="p">,</span> <span class="n">delimiter</span><span class="o">=</span><span class="s">","</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
</code></pre></div></div>

<p>Mamy gotowy już nasz <code class="highlighter-rouge">X</code> i <code class="highlighter-rouge">y</code>, jeżeli jednak chcemy aby nasze badania nosiły chociażby znamiona rzetelności, to w żadnym razie nie możemy na tym poprzestać.</p>

<h3 id="podział-danych-na-zbiór-uczący-oraz-zbiór-testowy">Podział danych na zbiór uczący oraz zbiór testowy</h3>

<p>Przed wykonaniem jakichkolwiek badań musimy pamiętać, aby podzielić nasz zestaw danych na <em>zbiór uczący</em> oraz <em>zbiór testowy</em>. W zadaniu klasyfikacji <em>zbiór uczący</em> zawiera znane nam instancje problemu, które zostały wcześniej poetykietowane i posłużą do wytrenowania wybranego przez nas modelu, aby potem mógł on generalizować zdobytą wiedzę w odniesieniu do instancji, których wcześniej nie widział (czyli <em>zbioru testowego</em>). Trenowanie i testowanie modelu na tym samym zbiorze danych jest absolutnie niedopuszczalne i uzyskane w ten sposób wyniki w żaden sposób nie odzwierciedlają faktycznej zdolności predykcyjnej klasyfikatora.</p>

<p>W dzisiejszym przykładzie skorzystamy z funkcji <code class="highlighter-rouge">train_test_split()</code>, za której pomocą dokonamy pojedynczego podziału naszego zbioru danych. Jest to podejście zdecydowanie intelektualnie nienachalne i urągające godności naukowca, niemniej jednak przedstawimy je tutaj (<strong>i tylko tutaj</strong>) jako najprostszy możliwy przykład podziału danych na potrzeby zadania klasyfikacji. W przyszłą środę nauczymy się używać <em>walidacji krzyżowej</em>, która pozwoli nam na rzetelne przeprowadzenie badań i to właśnie z niej będziemy korzystać we wszystkich przyszłych starciach z uczeniem maszynowym.</p>

<p>Wracając jednak do teraźniejszości, przygotujmy nasz <em>zbiór testowy</em> oraz <em>zbiór uczący</em> za pomocą <code class="highlighter-rouge">train_test_split()</code>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">.3</span><span class="p">,</span>
    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span>
<span class="p">)</span>
</code></pre></div></div>
<p>W tym przypadku, jako argumenty funkcji, przekazać musimy tylko dwa parametry t.j. dobrze już nam znany i lubiany <code class="highlighter-rouge">random_state</code> oraz <code class="highlighter-rouge">test_size</code>, który mówi nam o tym, jaki procent wszystkich danych zostanie wykorzystany do testowania naszego modelu. Tutaj decydujemy się na wykorzystanie 70% danych do uczenia oraz 30% do testowania klasyfikatora.</p>

<h2 id="klasyfikacja">Klasyfikacja</h2>

<h3 id="inicjalizacja-i-budowa-modelu-klasyfikacji">Inicjalizacja i budowa modelu klasyfikacji</h3>

<p>Teraz, gdy przygotowaliśmy już nasze dane, możemy w końcu przejść do inicjalizacji oraz wytrenowania modelu klasyfikacji. Skorzystamy z prostego klasyfikatora probabilistycznego, którym jest <em>Naiwny klasyfikator bayesowski</em> w wersji opartej na rozkładzie normalnym (rozkładzie Gaussa). Jest on nazywany <em>naiwnym</em>, ponieważ zakłada niezależność od siebie cech problemu, a implementuje go klasa <code class="highlighter-rouge">GaussianNB</code>.</p>

<p>W celu dopasowania naszego modelu do danych uczących wywołujemy metodę <code class="highlighter-rouge">fit()</code>, która przyjmuje kolejno <em>zbiór danych</em> oraz <em>zbiór etykiet</em> naszego zbioru uczącego:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</code></pre></div></div>
<p>Nasz model został już wyuczony na poetykietowanych danych, możemy więc w końcu przystąpić do predykcji.</p>

<h3 id="wyznaczenie-macierzy-wsparcia-oraz-predykcji">Wyznaczenie macierzy wsparcia oraz predykcji</h3>

<p>Klasyfikatory zaimplementowane w bibliotece <code class="highlighter-rouge">scikit-learn</code> implementują metodę <code class="highlighter-rouge">predict()</code>, która pozwala nam na bezpośrednie uzyskanie etykiet przyporządkowanych nieznanym instancjom przez klasyfikator. My jednak, żeby nie było tak łatwo, nie skorzystamy z tej metody.</p>

<p>Dzięki temu, że zastosowany przez nas model jest probabilistyczny, możemy poprosić go o zwrócenie <em>macierzy wsparć</em>. Liczba wierszy tej macierzy jest równa liczbie instancji problemu w <em>zbiorze testowym</em> (czyli u nas 30), a liczba kolumn równa jest liczbie klas problemu (w naszym przypadku problem jest binarny, więc mamy dwie kolumny). Każdy z wierszy macierzy odpowiada <em>wektorowi wsparć</em> zwróconemu przez model dla danej klasyfikowanej instancji problemu. Wartości w tym wektorze mówią nam o tym, z jakim prawdopodobieństwem klasyfikowana instancja należy do danej klasy. <em>Macierz wsparć</em> uzyskać możemy korzystając z metody <code class="highlighter-rouge">predict_proba()</code> i podając jako jej argument nasz testowy zbiór danych:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">class_probabilities</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Class probabilities:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">class_probabilities</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Class probabilities:
&gt;&gt; [[2.57883436e-06 9.99997421e 01]
&gt;&gt; [1.99658559e-06 9.99998003e-01]
&gt;&gt; [9.90973563e-01 9.02643748e-03]
&gt;&gt; [5.47593735e-05 9.99945241e-01]
&gt;&gt; [9.98382405e-01 1.61759531e-03]
...
</code></pre></div></div>

<p>Posiadając wiedzę o prawdopodobieństwach przynależności instancji ze <em>zbioru testowego</em> do klas, możemy w prosty sposób wyznaczyć predykcję. Zrobimy to zakładając, że każda z instancji testowych należy do tej klasy problemu, dla której prawdopodobieństwo przynależności jest największe.</p>

<p>Możemy dokonać tego bardzo sprawnie za pomocą funkcji <code class="highlighter-rouge">argmax()</code>, która zwróci nam dla każdego wiersza indeks kolumny, w której wystąpiła największa wartość. W tym celu podajemy jako argumenty wcześniej uzyskaną <em>macierz wsparć</em> oraz oś, po której chcemy się poruszać:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predict</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">class_probabilities</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Predicted labels:</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Predicted labels:
&gt;&gt; [1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0]
</code></pre></div></div>

<p>W celach całkowicie ilustracyjnych, wypiszemy teraz obok siebie prawdziwe etykiety naszego <em>zbioru testowego</em> (<code class="highlighter-rouge">y_test</code>) oraz wyznaczoną przez nas predykcję (<code class="highlighter-rouge">predict</code>):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="s">"True labels:     "</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Predicted labels:"</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; True labels:      [1 1 0 1 0 1 1 0 1 0 1 0 1 1 0 1 1 0 0 1 0 1 1 1 1 1 0 0 0 0]
&gt;&gt; Predicted labels: [1 1 0 1 0 0 1 0 1 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 1 0 0 0 0]
</code></pre></div></div>

<p>Jako, że mamy tutaj do czynienia zaledwie z 30 instancjami problemu, już na pierwszy rzut oka możemy stwierdzić, że oba wektory nieznacznie różnią się od siebie. Świadczy to o tym, że nasza predykcja nie jest idealna (i w praktyce nigdy idealna nie będzie), ale oczywiście ocena działania naszego modelu w ten sposób byłaby niewygodna. Potrzebujemy konkretnej wartości, która powiem nam jak dobry w tym przypadku jest nasz klasyfikator.</p>

<h3 id="ocena-jakości-klasyfikacji-naszego-modelu">Ocena jakości klasyfikacji naszego modelu</h3>

<p>Udało nam się dotrzeć do ostatniego dzisiejszego zagadnienia, a mianowicie do oceny jakości klasyfikacji. Istnieje wiele metryk ewaluacji (o nich nauczymy się później przy okazji rozmowy o danych niezbalansowanych), ale w dzisiejszym przykładzie wystarczy nam najprostsza z nich, a mianowicie jakość klasyfikacji. Informuje nas ona o tym, jaki procent instancji w <em>zbiorze testowym</em> został przez nas zaklasyfikowany poprawnie i sprawdza się w przypadku problemów zbalansowanych, czyli takich, w których liczba instancji należących do obu klas jest stosunkowo podobna.</p>

<p>Klasyfikatory w bibliotece <code class="highlighter-rouge">scikit-learn</code> implementują metodę <code class="highlighter-rouge">score()</code>, która pozwala nam na wyznaczenie jakości klasyfikacji. My jednak skorzystamy z osobnej funkcji <code class="highlighter-rouge">accuracy_score()</code>, dzięki której uzyskamy tą wartość na podstawie wyznaczonej przez nas w poprzednim kroku predykcji. W ten sposób przyzwyczaimy się do samodzielnego przeprowadzania predykcji i wyznaczania metryki ewaluacji, co okaże się konieczne w przypadku budowania własnych modeli klasyfikacji (zwłaszcza zespołowych) oraz radzenia sobie z danymi niezbalansowanymi.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Accuracy score:</span><span class="se">\n</span><span class="s"> </span><span class="si">%.2</span><span class="s">f"</span> <span class="o">%</span> <span class="n">score</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Accuracy score:
&gt;&gt; 0.93
</code></pre></div></div>

<p>Jak widzimy, nasz model osiągnął 93% jakości klasyfikacji. Jest to wynik bardzo dobry, ale niestety wynikający głównie z prostoty problemu, którym się dzisiaj zajmowaliśmy.</p>

<p>Dodatkowo, jeżeli chcemy dowiedzieć się więcej o tym jak nasz model się zachował, możemy wyznaczyć za pomocą funkcji <code class="highlighter-rouge">confusion_matrix()</code> dobrze znaną nam z wykładu <em>macierz konfuzji</em>:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">predict</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Confusion matrix: </span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">cm</span><span class="p">)</span>
</code></pre></div></div>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&gt;&gt; Confusion matrix:
&gt;&gt; [[13  0]
&gt;&gt; [ 2 15]]
</code></pre></div></div>

<p>Dzięki temu dowiedzieliśmy się, że nasz klasyfikator popełnił dwa błędy polegające na zaklasyfikowaniu obiektu klasy pozytywnej jako obiekt klasy negatywnej (wartość False Negative = 2).</p>

<p>Uff, to już wszystko na dzisiaj. W przyszłą środę nauczymy się przeprowadzać eksperymenty po ludzku, czyli z wykorzystaniem <em>walidacji krzyżowej</em>. A do tego czasu możemy być dumni ze zdobytej dziś podstawowej wiedzy!</p>

<p><img src="/examples/kod2neo.jpg" alt="" /></p>
:ET